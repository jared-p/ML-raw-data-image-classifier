{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8da678",
   "metadata": {},
   "source": [
    "# ENGR481 Project Stage 1\n",
    "\n",
    "By: Jared Paull (63586572), Liam Ross (75469692)\n",
    "\n",
    "\n",
    "The first step that must be taken is to import the necessary libraries for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5233a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05346c",
   "metadata": {},
   "source": [
    "## Scraping Image Data\n",
    "\n",
    "Next, the training data must be loaded into a 2D numpy array. The first dimention of the array represents a sample, which in this context is a picture. Then each pixel contained of an image represents a feature of the dataset. This means that the total number of features is equal to the total number of pixels in the image.\n",
    "\n",
    "To do this, first the training images must be loaded into an array. Each image must be grayscaled, normalized in size, then scaled down to reduce the memory requirements of the algorithm. Simultaniously, each sample must have a corresponding label so that the algorithm can later correctly train a model from the data paired with the correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6596544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131 131 132 ... 159 159 160]\n",
      " [208 207 208 ... 199 199 200]\n",
      " [206 206 206 ... 196 195 196]\n",
      " ...\n",
      " [143 143 142 ... 197 196 196]\n",
      " [180 181 181 ... 206 206 205]\n",
      " [196 196 195 ... 220 220 222]] \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# first, an empty list is created so that image pixel arrays can be later added to it\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# create a for loop that will iterate through all items in the relative directory that contains the training image data\n",
    "for pic in os.listdir(\"../data/training/\"):\n",
    "    # import image using Pillow library, then convert the image to grayscale imediatly\n",
    "    image = PIL.Image.open(f\"../data/training/{pic}\").convert(\"L\")\n",
    "    # crop the image, will crop vertically from height/4 to 3*height/4\n",
    "    # and crop horizontally from width/4 to 3*height/4\n",
    "    # this will crop the image to reduce memory to only relevant pixels\n",
    "    image = PIL.Image.fromarray(np.array(image)[int(np.floor(image.height / 4)) : int(np.ceil(3 * image.height / 4)), int(np.floor(image.width / 4)) : int(np.ceil( 3 * image.width / 4))])\n",
    "    # resizes the image to 64x64 pixels, ensures the number of feature vectors are constant regardless of raw image file.\n",
    "    # resizing also reduces the total memory requirements of the algorithm.\n",
    "    image = image.resize((64,64))\n",
    "    # converts from image format to a 2D array representing a pixel grid\n",
    "    data = np.asarray(image)\n",
    "    # converts from a 2D pixel grid to a 1D array of length 64^2=4096, where the rows are appended horizontally.\n",
    "    vec = np.hstack(data)\n",
    "    # add the image data to the container of all images.\n",
    "    x.append(vec)\n",
    "    \n",
    "    # examine the name of the picture file, can find correct label based on first letter of the file name.\n",
    "    # c indicates the picture is a circle\n",
    "    if( str.lower(pic[0]) == \"c\"):\n",
    "        # classify circles as a 0\n",
    "        y.append(0)\n",
    "    # r indicates the picture is a rectangle\n",
    "    elif (str.lower(pic[0]) == \"r\"):\n",
    "        # classify rectangle as a 1\n",
    "        y.append(1)\n",
    "    # only other situation is the image is a square\n",
    "    else:\n",
    "        # classify square as a 2\n",
    "        y.append(2)\n",
    "    \n",
    "# convert from python list to numpy array, format is required for sklearn logistic regression solver.\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# print statement to get a feel for the data\n",
    "# Each row of x are all 4096 pixels of an image\n",
    "# Each value of y indicates the class, where the index of y correlates to the row of x (linking image data and label).\n",
    "print(x,\"\\n\", y);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05164fa0",
   "metadata": {},
   "source": [
    "### Creating Logistic Regression Model\n",
    "\n",
    "Now that all of the image data is collected, and they have a corresponding label. The data can be fit to a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfee65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating logistic regression model instance that implements a liblinear solver type\n",
    "# liblinear solver implements a coordinate descent algorithm which works well with high dimension (4096 here)\n",
    "log_regress = linear_model.LogisticRegression(solver = \"liblinear\")\n",
    "# method to fit the logistic regression instance with the data collected in the previous cell\n",
    "log_regress.fit(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c935e7c5",
   "metadata": {},
   "source": [
    "## Testing the algorithm\n",
    "\n",
    "Now that a model exists, image data and labels are scraped from the testing folder, in the exact same fashion as the data collection from the training data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166818de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196 195 196 ... 190 191 190]\n",
      " [124 126 127 ... 150 150 151]\n",
      " [166 166 165 ... 180 180 180]\n",
      " ...\n",
      " [170 169 168 ... 158 158 159]\n",
      " [166 165 165 ... 155 156 155]\n",
      " [162 161 161 ... 158 157 158]] \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# The code here is the same as that used to get image data from the training folder.\n",
    "# This section will not be commented on, since the previous section covers all aspects of it.\n",
    "# xt,yt represent image (x) training data, and label (y) training data\n",
    "\n",
    "xt = []\n",
    "yt = []\n",
    "for pic in os.listdir(\"../data/testing/\"):\n",
    "    image = PIL.Image.open(f\"../data/testing/{pic}\").convert(\"L\")\n",
    "    image = PIL.Image.fromarray(np.array(image)[int(np.floor(image.height / 4)) : int(np.ceil(3 * image.height / 4)), int(np.floor(image.width / 4)) : int(np.ceil( 3 * image.width / 4))])\n",
    "    image = image.resize((64,64))\n",
    "    data = np.asarray(image)\n",
    "    vec = np.hstack(data)\n",
    "    xt.append(vec)\n",
    "    \n",
    "    if( str.lower(pic[0]) == \"c\"):\n",
    "        yt.append(0)\n",
    "    elif (str.lower(pic[0]) == \"r\"):\n",
    "        yt.append(1)\n",
    "    else:\n",
    "        yt.append(2)\n",
    "    \n",
    "xt = np.array(xt)\n",
    "yt = np.array(yt)\n",
    "\n",
    "print(xt, \"\\n\", yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80464d0a",
   "metadata": {},
   "source": [
    "## Prediction and Confusion Matrix\n",
    "\n",
    "The training data is fed into the model and an output is predicted (based on the model). Then the outputs from the model are compared with the correct values to see the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d90b777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape      Circle  Rectangle  Square\n",
      "Circle         17          0       1\n",
      "Rectangle       0         17       1\n",
      "Square          1          0      17\n",
      "\n",
      "Percentage of model errors from the training data: 5.56%\n"
     ]
    }
   ],
   "source": [
    "# feed the training data into the model, pred is an array containing the output labels based on the model\n",
    "pred =  log_regress.predict(xt)\n",
    "\n",
    "# These are two formatting questions to make the confusion matrix more appealing. Refer to confusion_format function at the bottom.\n",
    "predicted = confusion_format(pred)\n",
    "actual = confusion_format(y)\n",
    "\n",
    "# prints a confusion matrix, rows are true values, and columns are the model's guessed values.\n",
    "print(pd.crosstab(actual, predicted, rownames=[None], colnames=[\"Shape\"]))\n",
    "\n",
    "# the number of errors is the number of differences between the model's labels and the correct labels\n",
    "errors = 0\n",
    "for i in range(pred.size):\n",
    "    if pred[i] != y[i]:\n",
    "        errors = errors + 1\n",
    "\n",
    "# then the percentage of errors is the number of errors divided by the total number of image samples times 100 for percentage.\n",
    "percentage_errors = errors / pred.size * 100\n",
    "print(f\"\\nPercentage of model errors from the training data: {percentage_errors:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf53ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a76277db",
   "metadata": {},
   "source": [
    "## Model Accuracy\n",
    "\n",
    "Baised on the testing data, the trained model is ~95% accurate.\n",
    "\n",
    "## Functions Used Elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d15f3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will convert from decimal label to strings.\n",
    "# 0=>Circle, 1=>Rectangle, 2=>Square\n",
    "\n",
    "def confusion_format(labels):\n",
    "    test = []\n",
    "    for i in labels:\n",
    "        if i == 0:\n",
    "            test.append(\"Circle\")\n",
    "        elif i == 1:\n",
    "            test.append(\"Rectangle\")\n",
    "        else:\n",
    "            test.append(\"Square\")\n",
    "    test = np.array(test)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24137a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(rel_dir):\n",
    "\n",
    "    # first, an empty list is created so that image pixel arrays can be later added to it\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    # create a for loop that will iterate through all items in the relative directory that contains the training image data\n",
    "    for pic in os.listdir(f\"{rel_dir}/\"):\n",
    "        # import image using Pillow library, then convert the image to grayscale imediatly\n",
    "        image = PIL.Image.open(f\"{rel_dir}/{pic}\").convert(\"L\")\n",
    "        # crop the image, will crop vertically from height/4 to 3*height/4\n",
    "        # and crop horizontally from width/4 to 3*height/4\n",
    "        # this will crop the image to reduce memory to only relevant pixels\n",
    "        image = PIL.Image.fromarray(np.array(image)[int(np.floor(image.height / 4)) : int(np.ceil(3 * image.height / 4)), int(np.floor(image.width / 4)) : int(np.ceil( 3 * image.width / 4))])\n",
    "        # resizes the image to 64x64 pixels, ensures the number of feature vectors are constant regardless of raw image file.\n",
    "        # resizing also reduces the total memory requirements of the algorithm.\n",
    "        image = image.resize((64,64))\n",
    "        # converts from image format to a 2D array representing a pixel grid\n",
    "        data = np.asarray(image)\n",
    "        # converts from a 2D pixel grid to a 1D array of length 64^2=4096, where the rows are appended horizontally.\n",
    "        vec = np.hstack(data)\n",
    "        # add the image data to the container of all images.\n",
    "        x.append(vec)\n",
    "    \n",
    "        # examine the name of the picture file, can find correct label based on first letter of the file name.\n",
    "        # c indicates the picture is a circle\n",
    "        if( str.lower(pic[0]) == \"c\"):\n",
    "            # classify circles as a 0\n",
    "            y.append(0)\n",
    "        # r indicates the picture is a rectangle\n",
    "        elif (str.lower(pic[0]) == \"r\"):\n",
    "            # classify rectangle as a 1\n",
    "            y.append(1)\n",
    "        # only other situation is the image is a square\n",
    "        else:\n",
    "            # classify square as a 2\n",
    "            y.append(2)\n",
    "    \n",
    "    # convert from python list to numpy array, format is required for sklearn logistic regression solver.\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y\n",
    "    # print statement to get a feel for the data\n",
    "    # Each row of x are all 4096 pixels of an image\n",
    "    # Each value of y indicates the class, where the index of y correlates to the row of x (linking image data and label).\n",
    "    #print(x,\"\\n\", y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4777a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eefede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
